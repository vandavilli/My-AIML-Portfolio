{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Recommender system with Surprise\n",
    "\n",
    "This try-it focuses on exploring additional algorithms with the `Suprise` library to generate recommendations.  Your goal is to identify the optimal algorithm by minimizing the mean squared error using cross validation. You are also going to select a dataset to use from [grouplens](https://grouplens.org/datasets/movielens/) example datasets.  \n",
    "\n",
    "To begin, head over to grouplens and examine the different datasets available.  Choose one so that it is easy to create the data as expected in `Surprise` with user, item, and rating information.  Then, compare the performance of at least the `KNNBasic`, `SVD`, `NMF`, `SlopeOne`, and `CoClustering` algorithms to build your recommendations.  For more information on the algorithms see the documentation for the algorithm package [here](https://surprise.readthedocs.io/en/stable/prediction_algorithms_package.html).\n",
    "\n",
    "Share the results of your investigation and include the results of your cross validation and a basic description of your dataset with your peers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader, SVD, NMF, KNNBasic, SlopeOne, CoClustering\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadBookRatingsData():\n",
    "    print(\"Loading user data ...\")\n",
    "    user = pd.read_csv('data/BX-Users.csv', sep=';', encoding=\"latin-1\")\n",
    "    print(\"Loading ratings data ...\")\n",
    "    ratings = pd.read_csv('data/BX-Book-Ratings.csv', sep=';', encoding=\"latin-1\")\n",
    "    print(\"Merge and return dataframe ...\")\n",
    "    df = pd.merge(user, ratings, on='User-ID', how='inner')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommenderMetrics(predictions):\n",
    "    mae = accuracy.mae(predictions, verbose=False)\n",
    "    rmse = accuracy.rmse(predictions, verbose=False)\n",
    "    return (mae, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = loadBookRatingsData()\n",
    "df.drop(['Location','Age'], axis=1, inplace=True)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots to understand the ratings distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_ratings = df['Book-Rating'].value_counts().sort_index(ascending=False)\n",
    "\n",
    "fig = px.bar(dist_ratings, x=dist_ratings.index, y=dist_ratings.values,\n",
    "             text = ['{:.1f} %'.format(val) for val in (dist_ratings.values / df.shape[0] * 100)],\n",
    "             hover_data=['Book-Rating'], color='Book-Rating',\n",
    "             title=\"Ratings Distribution\",\n",
    "             labels={'index':'Rating Scale (0-10)','y':'% of ratings rcvd.'}, height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_boundaries(df, variable, distance):\n",
    "    IQR = df[variable].quantile(0.75) - df[variable].quantile(0.25)\n",
    "    \n",
    "    lower_boundary = df[variable].quantile(0.25) - (IQR*distance)\n",
    "    upper_boundary = df[variable].quantile(0.75) + (IQR*distance)\n",
    "\n",
    "    return lower_boundary, upper_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lo, up = find_boundaries(df, 'ISBN', 1.5)\n",
    "outliers = np.where(df['ISBN'] > up, True, \n",
    "                    np.where(df['ISBN'] < lo, True, False))\n",
    "\n",
    "df.loc[~outliers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter rarely-rated books\n",
    "min_book_ratings = 25\n",
    "filter_1 = df['ISBN'].value_counts() > min_ratings\n",
    "filter_1 = filter_1[filter_1].index.tolist()\n",
    "\n",
    "# filter rarely-rating users\n",
    "min_user_ratings = 50\n",
    "filter_2 = df['User-ID'].value_counts() > min_user_ratings\n",
    "filter_2 = filter_2[filter_2].index.tolist()\n",
    "\n",
    "df_new = df[(df['ISBN'].isin(filter_1)) & (df['User-ID'].isin(filter_2))]\n",
    "print('Original data frame has--->:\\t{}'.format(df.shape))\n",
    "print('After applying filters---->:\\t{}'.format(df_new.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SURPRISE !!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(0, 9))\n",
    "#data = Dataset.load_from_df(df_new[['User-ID', 'ISBN', 'Book-Rating']], reader)\n",
    "data = Dataset.load_from_df(df[['User-ID', 'ISBN', 'Book-Rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator():\n",
    "    benchmark_results = []\n",
    "    algorithms = [KNNBasic(), SVD(), NMF(), SlopeOne(), CoClustering()]\n",
    "    for algorithm in algorithms:\n",
    "        cv_results = cross_validate(algorithm, data, measures=['MAE','RMSE'], cv=3, verbose=False)\n",
    "        tmp = pd.DataFrame.from_dict(cv_results).mean(axis=0)\n",
    "        tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['algorithm']))\n",
    "        benchmark_results.append(tmp)\n",
    "    \n",
    "    return benchmark_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = evaluator()\n",
    "pd.DataFrame(rs).set_index('algorithm').sort_values('test_rmse')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
