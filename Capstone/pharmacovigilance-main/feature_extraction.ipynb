{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345877ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec, Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f83a5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_word_embeddings(df, column, word_embeddings):\n",
    "    embeddings = []\n",
    "    for document in df[column]:\n",
    "        for word in document.split():\n",
    "            if word in word_embeddings:\n",
    "                embeddings.append(word_embeddings[word])\n",
    "    if len(embeddings) > 0:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return np.zeros_like(word_embeddings.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7862a065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_weighted_embeddings(df, column, word_embeddings):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_vectors = vectorizer.fit_transform(df[column])\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    \n",
    "    weighted_embeddings = []\n",
    "    for i, document in enumerate(df[column]):\n",
    "        tfidf_values = tfidf_vectors[i].toarray()[0]\n",
    "        embeddings = []\n",
    "        for j, word in enumerate(document.split()):\n",
    "            if word in word_embeddings:\n",
    "                word_embedding = word_embeddings[word]\n",
    "                tfidf_weight = tfidf_values[j]\n",
    "                weighted_embedding = word_embedding * tfidf_weight\n",
    "                embeddings.append(weighted_embedding)\n",
    "        if len(embeddings) > 0:\n",
    "            document_embedding = np.mean(embeddings, axis=0)\n",
    "        else:\n",
    "            document_embedding = np.zeros_like(word_embeddings.vector_size)\n",
    "        weighted_embeddings.append(document_embedding)\n",
    "    \n",
    "    return weighted_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0103cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_word_averaging(df, column, word_weights, word_embeddings):\n",
    "    embeddings = []\n",
    "    for i, document in enumerate(df[column]):\n",
    "        for j, word in enumerate(document.split()):\n",
    "            if word in word_embeddings:\n",
    "                word_embedding = word_embeddings[word]\n",
    "                word_weight = word_weights[i][j]\n",
    "                weighted_embedding = word_embedding * word_weight\n",
    "                embeddings.append(weighted_embedding)\n",
    "    if len(embeddings) > 0:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return np.zeros_like(word_embeddings.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999f4dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_doc2vec(df, column):\n",
    "    tagged_documents = [TaggedDocument(words=document.split(), tags=[i]) for i, document in enumerate(df[column])]\n",
    "    model = Doc2Vec(tagged_documents, vector_size=100, window=5, min_count=1, epochs=10)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5febe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec.load('path_to_word2vec_model')\n",
    "\n",
    "df = pd.read_csv('your_data.csv')\n",
    "\n",
    "df['average_embeddings'] = df.apply(lambda row: average_word_embeddings(row, 'text', word2vec_model.wv), axis=1)\n",
    "df['tfidf_weighted_embeddings'] = df.apply(lambda row: tfidf_weighted_embeddings(row, 'text', word2vec_model.wv), axis=1)\n",
    "df['weighted_average'] = df.apply(lambda row: weighted_word_averaging(row, 'text', your_word_weights, word2vec_model.wv), axis=1)\n",
    "df['doc2vec_embeddings'] = df.apply(lambda row: train_doc2vec(row, 'text').infer_vector(row['text']), axis=1)\n",
    "\n",
    "df.to_csv('phamacovigil_output_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
