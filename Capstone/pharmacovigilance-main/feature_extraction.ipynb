{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "345877ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string\n",
    "import spacy\n",
    "import colorlover as cl\n",
    "import random\n",
    "import shap\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from plotly.subplots import make_subplots\n",
    "from spacy import displacy\n",
    "from nltk.tokenize import TreebankWordTokenizer as twt\n",
    "from nltk.tokenize import TweetTokenizer as twt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec, Doc2Vec, KeyedVectors\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, FunctionTransformer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa90c7a",
   "metadata": {},
   "source": [
    "#### Load pre-trained word vectors from a binary file located at the specified path. The file contains word vectors in a format compatible with Word2Vec. Only the first 100,000 word vectors are loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "066a6281",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './biowordvec/BioWordVec_PubMed_MIMICIII_d200.vec.bin'\n",
    "model = KeyedVectors.load_word2vec_format(model_path, binary=True, limit=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b67431d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Columns (112,114,121,125,157,168,186,188,206,208,217,229,231,232,233,235,237,241,244,246,247,249,250,251,268,270,271,280,282,286,288,289,291,305,310,312,313,315,316,318,319,323,324,327,328,329,331,333,335,336,338,342,344,348,350,352,353,355,356,358,359,361) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "dev_data = pd.read_csv('data/dev.csv')\n",
    "\n",
    "data = pd.concat([train_data, test_data, dev_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bdf09f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected columns to be retained and rename them\n",
    "selected_columns = ['id', 'context', 'annotations/0/events/0/event_type', \n",
    "                    'annotations/0/events/0/Trigger/text/0/0', \n",
    "                    'annotations/0/events/0/Treatment/Drug/text/0/0','annotations/0/events/0/Effect/text/0/0']\n",
    "new_names = ['id', 'context', 'event_type', 'trigger_text', 'drug', 'drug_effect']\n",
    "df = data[selected_columns].rename(columns=dict(zip(selected_columns, new_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eac2659",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_mapping = {'Adverse_event': 1, 'Potential_therapeutic_event': 0}\n",
    "df['sentiment'] = df['event_type'].map(sentiment_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc59e31",
   "metadata": {},
   "source": [
    "#### Used instead of TF-IDF as its a more prevalent technique in sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f83a5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_word_embeddings(df, column, word_embeddings):\n",
    "    embeddings = []\n",
    "    for document in df[column]:\n",
    "        for word in document.split():\n",
    "            if word in word_embeddings:\n",
    "                embeddings.append(word_embeddings[word])\n",
    "    if len(embeddings) > 0:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return np.zeros_like(word_embeddings.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc5febe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['average_embeddings'] = df.apply(lambda row: average_word_embeddings(row, 'context', model), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b18176a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('phamacovigil_output_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb3028d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "      <th>event_type</th>\n",
       "      <th>trigger_text</th>\n",
       "      <th>drug</th>\n",
       "      <th>drug_effect</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>average_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>990658_1</td>\n",
       "      <td>A fatal case of pancytopenia due to levomeprom...</td>\n",
       "      <td>Adverse_event</td>\n",
       "      <td>due</td>\n",
       "      <td>levomepromazine</td>\n",
       "      <td>pancytopenia</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.22692822, 0.15035842, 0.21457776, 0.0808344...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1871</th>\n",
       "      <td>17655376_1</td>\n",
       "      <td>Pharmacokinetics of dapsone gel, 5% for the tr...</td>\n",
       "      <td>Potential_therapeutic_event</td>\n",
       "      <td>treatment</td>\n",
       "      <td>dapsone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.227062, 0.16987313, 0.15353839, 0.07344896,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3531</th>\n",
       "      <td>20925534_3</td>\n",
       "      <td>Proton-pump inhibitors (PPIs) are believed to ...</td>\n",
       "      <td>Potential_therapeutic_event</td>\n",
       "      <td>believed</td>\n",
       "      <td>Proton-pump inhibitors (PPIs)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.25976455, 0.16897154, 0.135644, 0.030140094...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>19104709_2</td>\n",
       "      <td>In contrast to chronic or subacute thyroiditis...</td>\n",
       "      <td>Potential_therapeutic_event</td>\n",
       "      <td>for</td>\n",
       "      <td>IFN-alpha</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.24489142, 0.21867579, 0.107363515, 0.015361...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2601</th>\n",
       "      <td>8641617_1</td>\n",
       "      <td>Although both patients recovered from the coli...</td>\n",
       "      <td>Potential_therapeutic_event</td>\n",
       "      <td>recovered</td>\n",
       "      <td>vancomycin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.28353158, 0.195971, 0.15358187, 0.07332772,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>19667003_2</td>\n",
       "      <td>PURPOSE: A case of carbamazepine-induced hyper...</td>\n",
       "      <td>Adverse_event</td>\n",
       "      <td>induced</td>\n",
       "      <td>carbamazepine</td>\n",
       "      <td>hyperammonemia</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.17367765, 0.03918988, 0.17666668, 0.0314042...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3433</th>\n",
       "      <td>18837734_1</td>\n",
       "      <td>Rosaceiform eruption induced by erlotinib.</td>\n",
       "      <td>Adverse_event</td>\n",
       "      <td>induced</td>\n",
       "      <td>erlotinib</td>\n",
       "      <td>Rosaceiform eruption</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.26265162, 0.10211046, 0.18507987, 0.0087879...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3369</th>\n",
       "      <td>16317298_1</td>\n",
       "      <td>Gemcitabine-related radiation recall in a pati...</td>\n",
       "      <td>Adverse_event</td>\n",
       "      <td>related</td>\n",
       "      <td>Gemcitabine</td>\n",
       "      <td>radiation recall</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.16886453, 0.20107986, 0.051484108, 0.004735...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>2327115_4</td>\n",
       "      <td>This article describes a patient with suspecte...</td>\n",
       "      <td>Adverse_event</td>\n",
       "      <td>induced</td>\n",
       "      <td>ciprofloxacin</td>\n",
       "      <td>interstitial nephritis</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.22166675, 0.14473964, 0.094159015, 0.005891...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>9754850_2</td>\n",
       "      <td>Like other atypical neuroleptics olanzapine is...</td>\n",
       "      <td>Adverse_event</td>\n",
       "      <td>show</td>\n",
       "      <td>olanzapine</td>\n",
       "      <td>reduced prevalence of extrapyramidal side effects</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.21889381, 0.08909936, 0.14526007, 0.0442822...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                            context  \\\n",
       "911     990658_1  A fatal case of pancytopenia due to levomeprom...   \n",
       "1871  17655376_1  Pharmacokinetics of dapsone gel, 5% for the tr...   \n",
       "3531  20925534_3  Proton-pump inhibitors (PPIs) are believed to ...   \n",
       "1894  19104709_2  In contrast to chronic or subacute thyroiditis...   \n",
       "2601   8641617_1  Although both patients recovered from the coli...   \n",
       "2644  19667003_2  PURPOSE: A case of carbamazepine-induced hyper...   \n",
       "3433  18837734_1         Rosaceiform eruption induced by erlotinib.   \n",
       "3369  16317298_1  Gemcitabine-related radiation recall in a pati...   \n",
       "155    2327115_4  This article describes a patient with suspecte...   \n",
       "1742   9754850_2  Like other atypical neuroleptics olanzapine is...   \n",
       "\n",
       "                       event_type trigger_text                           drug  \\\n",
       "911                 Adverse_event          due                levomepromazine   \n",
       "1871  Potential_therapeutic_event    treatment                        dapsone   \n",
       "3531  Potential_therapeutic_event     believed  Proton-pump inhibitors (PPIs)   \n",
       "1894  Potential_therapeutic_event          for                      IFN-alpha   \n",
       "2601  Potential_therapeutic_event    recovered                     vancomycin   \n",
       "2644                Adverse_event      induced                  carbamazepine   \n",
       "3433                Adverse_event      induced                      erlotinib   \n",
       "3369                Adverse_event      related                    Gemcitabine   \n",
       "155                 Adverse_event      induced                  ciprofloxacin   \n",
       "1742                Adverse_event         show                     olanzapine   \n",
       "\n",
       "                                            drug_effect  sentiment  \\\n",
       "911                                        pancytopenia          1   \n",
       "1871                                                NaN          0   \n",
       "3531                                                NaN          0   \n",
       "1894                                                NaN          0   \n",
       "2601                                                NaN          0   \n",
       "2644                                     hyperammonemia          1   \n",
       "3433                               Rosaceiform eruption          1   \n",
       "3369                                   radiation recall          1   \n",
       "155                              interstitial nephritis          1   \n",
       "1742  reduced prevalence of extrapyramidal side effects          1   \n",
       "\n",
       "                                     average_embeddings  \n",
       "911   [0.22692822, 0.15035842, 0.21457776, 0.0808344...  \n",
       "1871  [0.227062, 0.16987313, 0.15353839, 0.07344896,...  \n",
       "3531  [0.25976455, 0.16897154, 0.135644, 0.030140094...  \n",
       "1894  [0.24489142, 0.21867579, 0.107363515, 0.015361...  \n",
       "2601  [0.28353158, 0.195971, 0.15358187, 0.07332772,...  \n",
       "2644  [0.17367765, 0.03918988, 0.17666668, 0.0314042...  \n",
       "3433  [0.26265162, 0.10211046, 0.18507987, 0.0087879...  \n",
       "3369  [0.16886453, 0.20107986, 0.051484108, 0.004735...  \n",
       "155   [0.22166675, 0.14473964, 0.094159015, 0.005891...  \n",
       "1742  [0.21889381, 0.08909936, 0.14526007, 0.0442822...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc94e993",
   "metadata": {},
   "source": [
    "#### Fit a MultinomialNB & Print the Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f14f34cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9078674948240165\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        89\n",
      "           1       0.91      1.00      0.95       877\n",
      "\n",
      "    accuracy                           0.91       966\n",
      "   macro avg       0.45      0.50      0.48       966\n",
      "weighted avg       0.82      0.91      0.86       966\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('sentiment', axis=1),\n",
    "                                                    df['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "X_train_embeddings = np.array(X_train['average_embeddings'].tolist())\n",
    "X_test_embeddings = np.array(X_test['average_embeddings'].tolist())\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_embeddings)\n",
    "X_test_scaled = scaler.transform(X_test_embeddings)\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = nb_model.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed77f781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class': {0: '0', 1: '1'},\n",
       " 'precision': {0: '0.00', 1: '0.91'},\n",
       " 'recall': {0: '0.00', 1: '1.00'},\n",
       " 'f1-score': {0: '0.00', 1: '0.95'},\n",
       " 'support': {0: '89', 1: '877'}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = report.split('\\n')\n",
    "data = [line.split() for line in lines[2:-5]]\n",
    "columns = ['class', 'precision', 'recall', 'f1-score', 'support']\n",
    "df_report = pd.DataFrame(data, columns=columns)\n",
    "df_report.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7454ff73",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "- The model achieved a precision of 0.00 for the negative class (PTE), indicating that it did not correctly predict any instances of potential therapeutic events.\n",
    "- For the positive class (ADE), the model achieved a precision of 0.91, indicating that 91% of the predicted adverse events were correctly classified.\n",
    "- The model achieved a recall of 1.00 for the positive class, indicating that it correctly identified all instances of adverse events. However, it had a recall of 0.00 for the negative class, indicating that it failed to identify any potential therapeutic events."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285ac04b",
   "metadata": {},
   "source": [
    "### Test with Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0ed1560",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df = pd.read_csv('data/dev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84e83d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['id', 'context', 'annotations/0/events/0/event_type', \n",
    "                    'annotations/0/events/0/Trigger/text/0/0', \n",
    "                    'annotations/0/events/0/Treatment/Drug/text/0/0','annotations/0/events/0/Effect/text/0/0']\n",
    "new_names = ['id', 'context', 'event_type', 'trigger_text', 'drug', 'drug_effect']\n",
    "dev_df = dev_df[selected_columns].rename(columns=dict(zip(selected_columns, new_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67ff8ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_mapping = {'Adverse_event': 1, 'Potential_therapeutic_event': 0}\n",
    "dev_df['sentiment'] = dev_df['event_type'].map(sentiment_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1113fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s-]', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z\\s-]', '', text)\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    \n",
    "    tokens = text.split()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    cleaned_text = ' '.join(tokens)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b19d2aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text):\n",
    "    # Preprocess the text\n",
    "    preprocessed_text = preprocess_text(text)\n",
    "    \n",
    "    # Extract average word embeddings from the preprocessed text\n",
    "    features = average_word_embeddings(preprocessed_text, 'context', model)\n",
    "    scaled_features = scaler.transform(features.reshape(1, -1))\n",
    "    \n",
    "    # Make a prediction using the trained model\n",
    "    prediction = nb_model.predict(scaled_features)\n",
    "    \n",
    "    # Map the predicted sentiment to the corresponding label\n",
    "    sentiment = sentiment_mapping[prediction[0]]\n",
    "    \n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "229bf9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_word_embeddings_modified(text, word_embeddings):\n",
    "    embeddings = []\n",
    "    for word in text.split():\n",
    "        if word in word_embeddings:\n",
    "            word_embedding = word_embeddings[word]\n",
    "            embeddings.append(word_embedding)\n",
    "    if embeddings:\n",
    "        average_embedding = np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        average_embedding = np.zeros_like(word_embeddings.vector_size)\n",
    "    return average_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1adf4acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment_updated(text):\n",
    "    # Preprocess the text\n",
    "    preprocessed_text = preprocess_text(text)\n",
    "    \n",
    "    # Extract average word embeddings from the preprocessed text\n",
    "    features = average_word_embeddings_modified(preprocessed_text, model)\n",
    "    scaled_features = scaler.transform(features.reshape(1, -1))\n",
    "    \n",
    "    # Make a prediction using the trained model\n",
    "    prediction = nb_model.predict(scaled_features)\n",
    "    \n",
    "    # Map the predicted sentiment to the corresponding label\n",
    "    sentiment = \"0-Potential Therapeutic Event\" if prediction[0] == 0 else \"1-Adverse Event\"\n",
    "    \n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fbafd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_my_model():\n",
    "    random_number = random.randint(0, len(dev_df) - 1)\n",
    "    random_row = dev_df.iloc[random_number]\n",
    "    context = random_row['context']\n",
    "    predicted_sentiment = predict_sentiment_updated(context)\n",
    "    actual_sentiment = random_row['sentiment']\n",
    "\n",
    "    result = pd.DataFrame({'Context': [context],\n",
    "                           'Actual Sentiment': [actual_sentiment],\n",
    "                           'Predicted Sentiment': [predicted_sentiment]})\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cebc14df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Actual Sentiment</th>\n",
       "      <th>Predicted Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>To our knowledge, however, this is the first c...</td>\n",
       "      <td>1</td>\n",
       "      <td>1-Adverse Event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This severe illness was likely caused by minoc...</td>\n",
       "      <td>1</td>\n",
       "      <td>1-Adverse Event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aseptic meningitis, hemolytic anemia, hepatiti...</td>\n",
       "      <td>1</td>\n",
       "      <td>1-Adverse Event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Although this G-CSF-driven leucocytosis was al...</td>\n",
       "      <td>1</td>\n",
       "      <td>1-Adverse Event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The successful development and implementation ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1-Adverse Event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A case of toxic hepatitis caused by combinatio...</td>\n",
       "      <td>1</td>\n",
       "      <td>1-Adverse Event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Artemether-lumefantrine (AL) is first-line tre...</td>\n",
       "      <td>0</td>\n",
       "      <td>1-Adverse Event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Azathioprine-induced myelosuppression due to t...</td>\n",
       "      <td>1</td>\n",
       "      <td>1-Adverse Event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>We report a case of generalized cutaneous scle...</td>\n",
       "      <td>1</td>\n",
       "      <td>1-Adverse Event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lipoid pneumonia: a silent complication of min...</td>\n",
       "      <td>1</td>\n",
       "      <td>1-Adverse Event</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Context  Actual Sentiment  \\\n",
       "0  To our knowledge, however, this is the first c...                 1   \n",
       "1  This severe illness was likely caused by minoc...                 1   \n",
       "2  Aseptic meningitis, hemolytic anemia, hepatiti...                 1   \n",
       "3  Although this G-CSF-driven leucocytosis was al...                 1   \n",
       "4  The successful development and implementation ...                 1   \n",
       "5  A case of toxic hepatitis caused by combinatio...                 1   \n",
       "6  Artemether-lumefantrine (AL) is first-line tre...                 0   \n",
       "7  Azathioprine-induced myelosuppression due to t...                 1   \n",
       "8  We report a case of generalized cutaneous scle...                 1   \n",
       "9  Lipoid pneumonia: a silent complication of min...                 1   \n",
       "\n",
       "  Predicted Sentiment  \n",
       "0     1-Adverse Event  \n",
       "1     1-Adverse Event  \n",
       "2     1-Adverse Event  \n",
       "3     1-Adverse Event  \n",
       "4     1-Adverse Event  \n",
       "5     1-Adverse Event  \n",
       "6     1-Adverse Event  \n",
       "7     1-Adverse Event  \n",
       "8     1-Adverse Event  \n",
       "9     1-Adverse Event  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for _ in range(10):\n",
    "    result = test_my_model()\n",
    "    results.append(result)\n",
    "\n",
    "output_df = pd.concat(results, ignore_index=True)\n",
    "\n",
    "output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a159de6",
   "metadata": {},
   "source": [
    "### Ensemble - LDA & NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a86ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train_embeddings = np.array(X_train['average_embeddings'].tolist())\n",
    "X_test_embeddings = np.array(X_test['average_embeddings'].tolist())\n",
    "\n",
    "X_train_embeddings = np.abs(X_train_embeddings)\n",
    "X_test_embeddings = np.abs(X_test_embeddings)\n",
    "\n",
    "nmf = NMF(init='nndsvda')\n",
    "lda = LatentDirichletAllocation()\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', MinMaxScaler(feature_range=(0, 1))),\n",
    "    ('abs_transform', FunctionTransformer(np.abs)),\n",
    "    ('nmf', nmf),\n",
    "    ('lda', lda),\n",
    "    ('nb_model', nb_model)\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'lda__n_components': [5, 10, 15],\n",
    "    'nb_model__alpha': [0.1, 1.0, 10.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5)\n",
    "\n",
    "grid_search.fit(X_train_embeddings, y_train)\n",
    "\n",
    "y_pred = grid_search.predict(X_test_embeddings)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1de07c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e738d19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
