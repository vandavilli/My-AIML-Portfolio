{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Models and Vectorization Strategies for Text Classification\n",
    "\n",
    "This notebook focuses on weighing the positives and negatives of different estimators and vectorization strategies for a text classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data\n",
    "\n",
    "The dataset below is from [kaggle]() and contains a dataset named the \"ColBert Dataset\" created for this [paper](https://arxiv.org/pdf/2004.12765.pdf).  You are to use the text column to classify whether or not the text was humorous.  It is loaded and displayed below.\n",
    "\n",
    "**Note:** The original dataset contains 200K rows of data. It is best to try to use the full dtaset. If the original dataset is too large for your computer, please use the 'dataset-minimal.csv', which has been reduced to 100K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import warnings\n",
    "import string\n",
    "\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/dataset.csv')\n",
    "df['text'] = df['text'].apply(str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['humor'] = df['humor'].map({False: 0, True: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task\n",
    "\n",
    "\n",
    "**Text preprocessing:** As a pre-processing step, perform both `stemming` and `lemmatizing` to normalize your text before classifying. For each technique use both the `CountVectorize`r and `TfidifVectorizer` and use options for stop words and max features to prepare the text data for your estimator.\n",
    "\n",
    "**Classification:** Once you have prepared the text data with stemming lemmatizing techniques, consider `LogisticRegression`, `DecisionTreeClassifier`, and `MultinomialNB` as classification algorithms for the data. Compare their performance in terms of accuracy and speed.\n",
    "\n",
    "Share the results of your best classifier in the form of a table with the best version of each estimator, a dictionary of the best parameters and the best score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming function & removing stop words & punctuation\n",
    "def stemmer(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    swords = stopwords.words('english')\n",
    "    punctuation = string.punctuation\n",
    "    return ' '.join([stemmer.stem(w) for w in word_tokenize(text) if ((w not in swords) and (w not in punctuation))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(stemmer)\n",
    "y = df['humor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_s = CountVectorizer(stop_words='english')\n",
    "cv_s_train = cv_s.fit_transform(X_train)\n",
    "cv_s_test = cv_s.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_s = TfidfVectorizer(stop_words='english')\n",
    "tfidf_s_train = tfidf_s.fit_transform(X_train)\n",
    "tfidf_s_test = tfidf_s.transform(X_test)\n",
    "print(tfidf_s.get_feature_names_out()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_s_df = pd.DataFrame(cv_s_train.toarray(), columns=cv_s.get_feature_names_out())\n",
    "tfidf_s_df = pd.DataFrame(tfidf_s_train.toarray(), columns=tfidf_s.get_feature_names_out())\n",
    "\n",
    "print(cv_s_df.shape)\n",
    "print(tfidf_s_df.shape)\n",
    "\n",
    "# Check whether the DataFrames are equal\n",
    "print(cv_s_df.equals(tfidf_s_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatizing function & removing stop words\n",
    "def lemmatizer(text):\n",
    "    lemma = WordNetLemmatizer()\n",
    "    swords = stopwords.words('english')\n",
    "    punctuation = string.punctuation\n",
    "    return ' '.join([lemma.lemmatize(w) for w in word_tokenize(text) if ((w not in swords) and (w not in punctuation))\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['text'] = df2['text'].apply(lemmatizer)\n",
    "y = df2['humor']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df2['text'], y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_l = CountVectorizer(stop_words='english', max_features = 100)\n",
    "cv_l_train = cv_l.fit_transform(X_train)\n",
    "cv_l_test = cv_l.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_l = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "tfidf_l_train = tfidf_l.fit_transform(X_train)\n",
    "tfidf_l_test = tfidf_l.transform(X_test)\n",
    "print(tfidf_l.get_feature_names_out()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_l_df = pd.DataFrame(cv_l_train.toarray(), columns=cv_l.get_feature_names_out())\n",
    "tfidf_l_df = pd.DataFrame(tfidf_l_train.toarray(), columns=tfidf_l.get_feature_names_out())\n",
    "\n",
    "print(cv_l_df.shape)\n",
    "print(tfidf_l_df.shape)\n",
    "\n",
    "# Check whether the DataFrames are equal\n",
    "print(cv_l_df.equals(tfidf_l_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pipe = Pipeline([('lr', LogisticRegression(random_state=42, max_iter = 1000))])\n",
    "dtc_pipe = Pipeline([('dtc', DecisionTreeClassifier(random_state=42))])\n",
    "\n",
    "params_logreg = {\n",
    "    'lr__penalty' : ['l1','l2'], \n",
    "    'lr__C'       : np.logspace(-3,3,7),\n",
    "    'lr__solver'  : ['newton-cg', 'lbfgs', 'liblinear']\n",
    "}\n",
    "\n",
    "params_dtc = {\n",
    "    'dtc__min_impurity_decrease': [0.01, 0.02, 0.03, 0.05],\n",
    "    'dtc__max_depth': [2, 5, 10],\n",
    "    'dtc__min_samples_split': [0.1, 0.2, 0.05]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_performance(pipe, params, X_train, y_train, X_test, y_test):\n",
    "    grid = GridSearchCV(pipe, \n",
    "                        param_grid=params, \n",
    "                        scoring='accuracy').fit(X_train, y_train)\n",
    "    \n",
    "    best_params = grid.best_params_\n",
    "    best_score = grid.score(X_test, y_test)\n",
    "    return {'best_params':best_params, 'best_score':best_score}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression & CV (stemming)\n",
    "lr_cv_s_dict = calculate_performance(logreg_pipe, params_logreg, cv_s_train, y_train, cv_s_test, y_test)\n",
    "lr_cv_s_best_params = lr_cv_s_dict['best_params']\n",
    "lr_cv_s_best_score = lr_cv_s_dict['best_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression & CV (lemmatizing)\n",
    "lr_cv_l_dict = calculate_performance(logreg_pipe, params_logreg, cv_l_train, y_train, cv_l_test, y_test)\n",
    "lr_cv_l_best_params = lr_cv_l_dict['best_params']\n",
    "lr_cv_l_best_score = lr_cv_l_dict['best_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression & TFIDF (stemming)\n",
    "lr_tfidf_s_dict = calculate_performance(logreg_pipe, params_logreg, tfidf_s_train, y_train, tfidf_s_test, y_test)\n",
    "lr_tfidf_s_best_params = lr_tfidf_s_dict['best_params']\n",
    "lr_tfidf_s_best_score = lr_tfidf_s_dict['best_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression & TFIDF (lemmatizing)\n",
    "lr_tfidf_l_dict = calculate_performance(logreg_pipe, params_logreg, tfidf_l_train, y_train, tfidf_l_test, y_test)\n",
    "lr_tfidf_l_best_params = lr_tfidf_l_dict['best_params']\n",
    "lr_tfidf_l_best_score = lr_tfidf_l_dict['best_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree classifier & CV (stemming)\n",
    "dtc_cv_s_dict = calculate_performance(dtc_pipe, params_dtc, cv_s_train, y_train, cv_s_test, y_test)\n",
    "dtc_cv_s_best_params = dtc_cv_s_dict['best_params']\n",
    "dtc_cv_s_best_score = dtc_cv_s_dict['best_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree classifier & CV (lemmatizing)\n",
    "dtc_cv_l_dict = calculate_performance(dtc_pipe, params_dtc, cv_l_train, y_train, cv_l_test, y_test)\n",
    "dtc_cv_l_best_params = dtc_cv_l_dict['best_params']\n",
    "dtc_cv_l_best_score = dtc_cv_l_dict['best_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree classifier & TFIDF (stemming)\n",
    "dtc_tfidf_s_dict = calculate_performance(dtc_pipe, params_dtc, tfidf_s_train, y_train, tfidf_s_test, y_test)\n",
    "dtc_tfidf_s_best_params = dtc_tfidf_s_dict['best_params']\n",
    "dtc_tfidf_s_best_score = dtc_tfidf_s_dict['best_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree classifier & TFIDF (lemmatizing)\n",
    "dtc_tfidf_l_dict = calculate_performance(dtc_pipe, params_dtc, tfidf_l_train, y_train, tfidf_l_test, y_test)\n",
    "dtc_tfidf_l_best_params = dtc_tfidf_l_dict['best_params']\n",
    "dtc_tfidf_l_best_score = dtc_tfidf_l_dict['best_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_nb = {\n",
    "    'nb__alpha' : np.arange(0, 1, .1)\n",
    "}\n",
    "nb_pipe = Pipeline([('nb', MultinomialNB())])\n",
    "\n",
    "def train_and_predict(X,y):\n",
    "    grid = GridSearchCV(nb_pipe, \n",
    "                        param_grid=params_nb, \n",
    "                        scoring='accuracy').fit(X, y)\n",
    "    best_params = grid.best_params_\n",
    "    best_score = grid.score(X, y)\n",
    "    return {'best_params':best_params, 'best_score':best_score}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_cv_s_dict=train_and_predict(cv_s_train, y_train)\n",
    "nb_cv_s_best_params = nb_cv_s_dict['best_params']\n",
    "nb_cv_s_best_score = nb_cv_s_dict['best_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_cv_l_dict=train_and_predict(cv_l_train, y_train)\n",
    "nb_cv_l_best_params = nb_cv_l_dict['best_params']\n",
    "nb_cv_l_best_score = nb_cv_l_dict['best_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_tfidf_s_dict=train_and_predict(tfidf_s_train, y_train)\n",
    "nb_tfidf_s_best_params = nb_tfidf_s_dict['best_params']\n",
    "nb_tfidf_s_best_score = nb_tfidf_s_dict['best_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_tfidf_l_dict=train_and_predict(tfidf_l_train, y_train)\n",
    "nb_tfidf_l_best_params = nb_tfidf_l_dict['best_params']\n",
    "nb_tfidf_l_best_score = nb_tfidf_l_dict['best_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(\n",
    "    {\n",
    "        'Model': ['LogisticRegression',' ',' ',' ',' ','DecisionTreeClassifier',' ',' ',' ',' ','MultinomalNB',' ',' ',' ',' '],\n",
    "        'Prep & Classification' : ['','CountVectorizer & Stemming','CountVectorizer & Lemmatization','TFIDF & Stemming','TFIDF & Lemmatization',\n",
    "                                  '','CountVectorizer & Stemming','CountVectorizer & Lemmatization','TFIDF & Stemming','TFIDF & Lemmatization',\n",
    "                                  '','CountVectorizer & Stemming','CountVectorizer & Lemmatization','TFIDF & Stemming','TFIDF & Lemmatization'],\n",
    "        'Best Params': ['',lr_cv_s_best_params,lr_cv_l_best_params,lr_tfidf_s_best_params,lr_tfidf_l_best_params,\n",
    "                       '',dtc_cv_s_best_params,dtc_cv_l_best_params,dtc_tfidf_s_best_params,dtc_tfidf_l_best_params,\n",
    "                        '',nb_cv_s_best_params,nb_cv_l_best_params,nb_tfidf_s_best_params,nb_tfidf_l_best_params],\n",
    "        'Best Score': ['',lr_cv_s_best_score,lr_cv_l_best_score,lr_tfidf_s_best_score,lr_tfidf_l_best_score,\n",
    "                      '',dtc_cv_s_best_score,dtc_cv_l_best_score,dtc_tfidf_s_best_score,dtc_tfidf_l_best_score,\n",
    "                      '',nb_cv_s_best_score,nb_cv_l_best_score,nb_tfidf_s_best_score,nb_tfidf_l_best_score]\n",
    "    }\n",
    ").set_index('Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", 10000)\n",
    "results_df.replace(np.nan,'',regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring the top 2 classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting with best logisticregression model - TDIF & lemmatization\n",
    "best_lr_model = LogisticRegression(C=10, penalty='l2', solver='lbfgs', random_state=42, max_iter = 1000)\n",
    "best_lr_model.fit(tfidf_l_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_predictions = best_lr_model.predict(tfidf_l_test)\n",
    "lr_score = best_lr_model.score(tfidf_l_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay.from_estimator(best_lr_model, tfidf_l_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting with best MultinomialNB model - TDIF & lemmatization\n",
    "nb_model =  MultinomialNB(alpha=0.7)\n",
    "nb_model.fit(tfidf_l_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_predictions = nb_model.predict(tfidf_l_test)\n",
    "print(nb_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay.from_estimator(nb_model, tfidf_l_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
